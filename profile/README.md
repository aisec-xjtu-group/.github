# üëã Welcome to the XJTU-AISEC open-source repository

[![Static Badge](https://img.shields.io/badge/CN-‰∏≠Êñá-red)](https://github.com/aisec-xjtu-group/.github/blob/main/profile/README-zh.md)

We are the Artificial Intelligence Security (AISEC) Research Group at Xi'an Jiaotong University (XJTU), focusing on various directions of AI security, including Adversarial Machine Learning, Multimedia Generation and Detection, Large Model Security, AI Testing, Trustworthy AI, and Intelligent Identity Security.

## üìä Repository Statistics

<!-- STATS_CARD_START -->
<div style="display: flex; justify-content: center;">
  <table style="border-collapse: collapse; width: 80%; background: #f4f4f4; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); text-align: center;">
    <tr>
      <td style="padding: 10px; font-weight: bold; text-align: center;">Total Repositories üìö</td>
      <td style="padding: 10px; text-align: center;">28</td>
    </tr>
    <tr>
      <td style="padding: 10px; font-weight: bold; text-align: center;">Total Stars ‚≠ê</td>
      <td style="padding: 10px; text-align: center;">1277</td>
    </tr>
    <tr>
      <td style="padding: 10px; font-weight: bold; text-align: center;">Total Forks üç¥</td>
      <td style="padding: 10px; text-align: center;">84</td>
    </tr>
  </table>
</div>
<!-- STATS_CARD_END -->

## üë©‚Äçüíª Repositories

| Direction | Paper | Repository |
| --- | --- | --- |
| Adversarial Machine Learning | [Improving Integrated  Gradient-based Transferable Adversarial Examples by Refining the Integration Path](https://ojs.aaai.org/index.php/AAAI/article/view/32722) (AAAI 2025) | [MuMoDIG](https://github.com/RYC-98/MuMoDIG) <img alt="Stars" src="https://img.shields.io/github/stars/RYC-98/MuMoDIG"> |
| Adversarial Machine Learning | [Improving Adversarial  Transferability on Vision Transformers via Forward Propagation Refinement](https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Improving_Adversarial_Transferability_on_Vision_Transformers_via_Forward_Propagation_Refinement_CVPR_2025_paper.html) (CVPR 2025) | [FPR](https://github.com/RYC-98/FPR) <img alt="Stars" src="https://img.shields.io/github/stars/RYC-98/FPR"> |
| Adversarial Machine Learning | [Revisiting Training-Inference  Trigger Intensity in Backdoor Attacks](https://www.usenix.org/conference/usenixsecurity25/presentation/lin-chenhao) (USENIX Security 2025) | [TITIM](https://github.com/cv12ha0/TITIM) <img alt="Stars" src="https://img.shields.io/github/stars/cv12ha0/TITIM"> |
| Adversarial Machine Learning | [Revisiting Transferable Adversarial Image Examples: Attack Categorization, Evaluation Guidelines, and New Insights](https://arxiv.org/abs/2310.11850) (arXiv 2025) | [TransferAttackEval](https://github.com/ZhengyuZhao/TransferAttackEval) <img alt="Stars" src="https://img.shields.io/github/stars/ZhengyuZhao/TransferAttackEval"> |
| Adversarial Machine Learning | [Collapse-Aware Triplet  Decoupling for Adversarially Robust Image Retrieval](https://ieeexplore.ieee.org/abstract/document/10418142) (ICML 2024) | [3D2Fool](https://github.com/Gandolfczjh/3D2Fool) <img alt="Stars" src="https://img.shields.io/github/stars/Gandolfczjh/3D2Fool"> |
| Adversarial Machine Learning | [Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving](http://arxiv.org/abs/2403.17301) (CVPR 2024) | [CA-TRIDE](https://github.com/michaeltian108/CA-TRIDE) <img alt="Stars" src="https://img.shields.io/github/stars/michaeltian108/CA-TRIDE"> |
| Adversarial Machine Learning | [Quantization Aware Attack: Enhancing the Transferability of Adversarial Attacks across Target Models with Different Quantization Bitwidths](https://ieeexplore.ieee.org/abstract/document/10418142) (TIFS 2024) | [QAA](https://github.com/yyl-github-1896/QAA) <img alt="Stars" src="https://img.shields.io/github/stars/yyl-github-1896/QAA"> |
| Adversarial Machine Learning | [Exploiting the Adversarial Example Vulnerability of Transfer Learning of Source Code](https://ieeexplore.ieee.org/abstract/document/10531252) (TIFS 2024) | [CodeTAE](https://github.com/yyl-github-1896/CodeTAE) <img alt="Stars" src="https://img.shields.io/github/stars/yyl-github-1896/CodeTAE"> |
| Adversarial Machine Learning | [Hard adversarial example mining for improving robust fairness](https://ieeexplore.ieee.org/abstract/document/10795188) (TIFS 2024) | [HAM](https://github.com/yyl-github-1896/HAM) <img alt="Stars" src="https://img.shields.io/github/stars/yyl-github-1896/HAM"> |
| Adversarial Machine Learning | [DREAM: Debugging and Repairing AutoML Pipelines](https://dl.acm.org/doi/full/10.1145/3702992) (TOSEM 2024) | [DREAM](https://github.com/shiningrain/DREAM) <img alt="Stars" src="https://img.shields.io/github/stars/shiningrain/DREAM"> |
| Adversarial Machine Learning | [Amplifying Membership Exposure via Data Poisoning](https://papers.neurips.cc/paper_files/paper/2022/file/c0f240bb986df54b38026398da1ae72a-Paper-Conference.pdf) (NeurIPS 2022) | [poisoning_membership](https://github.com/yfchen1994/poisoning_membership) <img alt="Stars" src="https://img.shields.io/github/stars/yfchen1994/poisoning_membership"> |
| Adversarial Machine Learning | [AUTOTRAINER: An Automatic DNN Training Problem Detection and Repair SystemTechnical](https://ieeexplore.ieee.org/abstract/document/9402077) (ICSE 2021) | [AUTOTRAINER](https://github.com/shiningrain/AUTOTRAINER) <img alt="Stars" src="https://img.shields.io/github/stars/shiningrain/AUTOTRAINER"> |
| Adversarial Machine Learning | [Seeing is Not Believing: Camouflage Attacks on Image Scaling Algorithms](https://www.usenix.org/system/files/sec19-xiao.pdf) (USENIX Security 2019) | [scaling_camouflage](https://github.com/yfchen1994/scaling_camouflage) <img alt="Stars" src="https://img.shields.io/github/stars/yfchen1994/scaling_camouflage"> |
| Multimedia Generation and Detection | [DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning](https://arxiv.org/abs/2505.14362) (arXiv 2025) | [DeepEyes](https://github.com/Visual-Agent/DeepEyes) <img alt="Stars" src="https://img.shields.io/github/stars/Visual-Agent/DeepEyes"> |
| Multimedia Generation and Detection | [Seeing It or Not? Interpretable Vision-aware Latent Steering to Mitigate Object Hallucinations](https://arxiv.org/abs/2505.17812) (arXiv 2025) | [VaLSe](https://github.com/Ziwei-Zheng/VaLSe) <img alt="Stars" src="https://img.shields.io/github/stars/Ziwei-Zheng/VaLSe"> |
| Multimedia Generation and Detection | [Breaking Semantic Artifacts for Generalized AI-generated Image Detection](https://proceedings.neurips.cc/paper_files/paper/2024/hash/6dddcff5b115b40c998a08fbd1cea4d7-Abstract-Conference.html) (NeurIPS 2024) | [FakeImageDetection](https://github.com/Zig-HS/FakeImageDetection) <img alt="Stars" src="https://img.shields.io/github/stars/Zig-HS/FakeImageDetection"> |
| Trustworthy AI | [Nullu: Mitigating Object Hallucinations in Large Vision-Language Models via HalluSpace Projection](https://arxiv.org/abs/2412.13817) (CVPR 2025) | [Nullu](https://github.com/Ziwei-Zheng/Nullu) <img alt="Stars" src="https://img.shields.io/github/stars/Ziwei-Zheng/Nullu"> |
| Trustworthy AI | [The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation](https://arxiv.org/abs/2501.07849) (ACL 2025) | [InvisibleHand](https://github.com/shiningrain/InvisibleHand) <img alt="Stars" src="https://img.shields.io/github/stars/shiningrain/InvisibleHand"> |
| Trustworthy AI | [Efficient DNN-Powered Software with Fair Sparse Models](https://arxiv.org/abs/2407.02805) (ISSTA 2024) | [Ballot](https://github.com/Antimony5292/Ballot) <img alt="Stars" src="https://img.shields.io/github/stars/Antimony5292/Ballot"> |
| Trustworthy AI | [CILIATE: Towards fairer class-based incremental learning by dataset and training refinement](https://arxiv.org/abs/2304.04222) (ISSTA 2023) | [CILIATE](https://github.com/Antimony5292/CILIATE) <img alt="Stars" src="https://img.shields.io/github/stars/Antimony5292/CILIATE"> |
| Trustworthy AI | [Teacher Model Fingerprinting Attacks Against Transfer Learning](https://www.usenix.org/system/files/sec22-chen-yufei.pdf) (USENIX Security 2022) | [Teacher-Fingerprinting](https://github.com/yfchen1994/Teacher-Fingerprinting) <img alt="Stars" src="https://img.shields.io/github/stars/yfchen1994/Teacher-Fingerprinting"> |
| Trustworthy AI | [FairNeuron: improving deep neural network fairness with adversary games on selective neurons](https://arxiv.org/abs/2204.02567) (ICSE 2022) | [FairNeuron](https://github.com/Antimony5292/FairNeuron) <img alt="Stars" src="https://img.shields.io/github/stars/Antimony5292/FairNeuron"> |
| AI Testing | [JailGuard: A Universal Detection Framework for Prompt-based Attacks on LLM Systems](https://dl.acm.org/doi/abs/10.1145/3724393) (TOSEM 2025) | [JailGuard](https://github.com/shiningrain/JailGuard) <img alt="Stars" src="https://img.shields.io/github/stars/shiningrain/JailGuard"> |
| AI Testing | [STAFF: Speculative Coreset Selection for Task-Specific Fine-tuning](https://openreview.net/forum?id=FAfxvdv1Dy) (ICLR 2025) | [STAFF](https://github.com/shiningrain/STAFF) <img alt="Stars" src="https://img.shields.io/github/stars/shiningrain/STAFF"> |
| AI Testing | [COSTELLO: Contrastive Testing for Embedding-based Large Language Model as a Service Embeddings](https://dl.acm.org/doi/10.1145/3643767) (FSE 2024) | [COSTELLO](https://github.com/lenijwp/COSTELLO) <img alt="Stars" src="https://img.shields.io/github/stars/lenijwp/COSTELLO"> |
| Large Model Security | [An Optimizable Suffix Is Worth A Thousand Templates: Efficient Black-box Jailbreaking without Affirmative Phrases via LLM as Optimizer](https://aclanthology.org/2025.findings-naacl.302) (NAACL Findings 2025) | [ECLIPSE](https://github.com/lenijwp/ECLIPSE) <img alt="Stars" src="https://img.shields.io/github/stars/lenijwp/ECLIPSE"> |
| Large Model Security | [Deep Learning Library Testing: Definition, Methods and Challenges](https://dl.acm.org/doi/abs/10.1145/3716497) (CSUR 2025) | [CSUR_DL_library_survey](https://github.com/shiningrain/CSUR_DL_library_survey) <img alt="Stars" src="https://img.shields.io/github/stars/shiningrain/CSUR_DL_library_survey"> |

## üí¨ Contact Us

| Contact üë§ | Email üìß |
| :---: | :---: |
| [Prof. Chao Shen](https://gr.xjtu.edu.cn/web/cshen/) | chaoshen@xjtu.edu.cn |
| [Prof. Chenhao Lin](https://gr.xjtu.edu.cn/web/linchenhao) | linchenhao@xjtu.edu.cn |
| [Prof. Zhengyu Zhao](https://zhengyuzhao.github.io/) | zhengyu.zhao@xjtu.edu.cn |
| [Prof. Le Yang](https://www.yangle.cc/) | yangle15@xjtu.edu.cn |
| Repository administrator: Yuheng Wang| yh.wang@stu.xjtu.edu.cn |
